+ module add gcc cuda cudnn
++ /usr/bin/modulecmd bash add gcc cuda cudnn
+ eval CC=/opt/local/stow/gcc-9.3.0/bin/gcc ';export' 'CC;CPATH=/opt/common/cudnn/cudnn-10.0-7.6.5/include:/opt/common/cuda/cuda-10.0.130/include:/opt/local/stow/gcc-9.3.0/include:/opt/local/stow/cloog-0.18.4/include' ';export' 'CPATH;CPPFLAGS=-I/opt/local/stow/isl-0.16.1/include\' '-I/opt/local/stow/mpc-1.0.3/include\' '-I/opt/local/stow/mpfr-3.1.4/include\' -I/opt/local/stow/gmp-6.1.1/include ';export' 'CPPFLAGS;CUDA_HOME=/opt/common/cuda/cuda-10.0.130' ';export' 'CUDA_HOME;CXX=/opt/local/stow/gcc-9.3.0/bin/g++' ';export' 'CXX;LDFLAGS=-L/opt/local/stow/isl-0.16.1/lib\' '-L/opt/local/stow/mpc-1.0.3/lib\' '-L/opt/local/stow/mpfr-3.1.4/lib\' -L/opt/local/stow/gmp-6.1.1/lib ';export' 'LDFLAGS;LD_LIBRARY_PATH=/opt/common/cudnn/cudnn-10.0-7.6.5/lib64:/opt/common/cuda/cuda-10.0.130/lib64:/opt/local/stow/gcc-9.3.0/lib64:/opt/local/stow/gcc-9.3.0/lib:/vulcan/scratch/kampta/.local/torch/lib:' ';export' 'LD_LIBRARY_PATH;LD_RUN_PATH=/opt/common/cudnn/cudnn-10.0-7.6.5/lib64:/usr/lib64/nvidia:/usr/lib/nvidia:/opt/common/cuda/cuda-10.0.130/lib64:/opt/common/cuda/cuda-10.0.130/lib:/opt/local/stow/gcc-9.3.0/lib64:/opt/local/stow/gcc-9.3.0/lib:/opt/local/stow/isl-0.16.1/lib:/opt/local/stow/cloog-0.18.4/lib:/opt/local/stow/mpc-1.0.3/lib:/opt/local/stow/mpfr-3.1.4/lib:/opt/local/stow/gmp-6.1.1/lib' ';export' 'LD_RUN_PATH;LIBRARY_PATH=/opt/common/cudnn/cudnn-10.0-7.6.5/lib64:/usr/lib64/nvidia:/usr/lib/nvidia:/opt/common/cuda/cuda-10.0.130/lib64:/opt/common/cuda/cuda-10.0.130/lib:/opt/local/stow/gcc-9.3.0/lib64:/opt/local/stow/gcc-9.3.0/lib:/opt/local/stow/cloog-0.18.4/lib' ';export' 'LIBRARY_PATH;LOADEDMODULES=gmp/6.1.1:mpfr/3.1.4:mpc/1.0.3:ppl/1.2:cloog/0.18.4:dejagnu/1.6:autogen/5.18.7:isl/0.16.1:gcc/9.3.0:cuda/10.0.130:cudnn/v7.6.5' ';export' 'LOADEDMODULES;MANPATH=/opt/local/stow/gcc-9.3.0/share/man:/opt/local/stow/autogen-5.18.7/share/man:/opt/local/stow/dejagnu-1.6/share/man:/opt/local/stow/ppl-1.2/share/man:/opt/puppetlabs/puppet/share/man' ';export' 'MANPATH;PATH=/opt/common/cuda/cuda-10.0.130/bin:/opt/local/stow/gcc-9.3.0/bin:/opt/local/stow/autogen-5.18.7/bin:/opt/local/stow/dejagnu-1.6/bin:/opt/local/stow/cloog-0.18.4/bin:/opt/local/stow/ppl-1.2/bin:/vulcanscratch/kampta/anaconda/envs/py36/bin:/vulcanscratch/kampta/anaconda/condabin:/vulcan/scratch/kampta/.local/torch/bin:/opt/local/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin' ';export' 'PATH;PKG_CONFIG_PATH=/opt/common/cuda/cuda-10.0.130/pkgconfig:/opt/local/stow/isl-0.16.1/lib/pkgconfig:/opt/local/stow/cloog-0.18.4/lib/pkgconfig' ';export' 'PKG_CONFIG_PATH;PPL_PATH=/opt/local/stow/ppl-1.2' ';export' 'PPL_PATH;_LMFILES_=/opt/local/stow/.modulefiles/gmp/6.1.1:/opt/local/stow/.modulefiles/mpfr/3.1.4:/opt/local/stow/.modulefiles/mpc/1.0.3:/opt/local/stow/.modulefiles/ppl/1.2:/opt/local/stow/.modulefiles/cloog/0.18.4:/opt/local/stow/.modulefiles/dejagnu/1.6:/opt/local/stow/.modulefiles/autogen/5.18.7:/opt/local/stow/.modulefiles/isl/0.16.1:/opt/local/stow/.modulefiles/gcc/9.3.0:/opt/common/.modulefiles/cuda/10.0.130:/opt/common/.modulefiles/cudnn/v7.6.5' ';export' '_LMFILES_;'
++ CC=/opt/local/stow/gcc-9.3.0/bin/gcc
++ export CC
++ CPATH=/opt/common/cudnn/cudnn-10.0-7.6.5/include:/opt/common/cuda/cuda-10.0.130/include:/opt/local/stow/gcc-9.3.0/include:/opt/local/stow/cloog-0.18.4/include
++ export CPATH
++ CPPFLAGS='-I/opt/local/stow/isl-0.16.1/include -I/opt/local/stow/mpc-1.0.3/include -I/opt/local/stow/mpfr-3.1.4/include -I/opt/local/stow/gmp-6.1.1/include'
++ export CPPFLAGS
++ CUDA_HOME=/opt/common/cuda/cuda-10.0.130
++ export CUDA_HOME
++ CXX=/opt/local/stow/gcc-9.3.0/bin/g++
++ export CXX
++ LDFLAGS='-L/opt/local/stow/isl-0.16.1/lib -L/opt/local/stow/mpc-1.0.3/lib -L/opt/local/stow/mpfr-3.1.4/lib -L/opt/local/stow/gmp-6.1.1/lib'
++ export LDFLAGS
++ LD_LIBRARY_PATH=/opt/common/cudnn/cudnn-10.0-7.6.5/lib64:/opt/common/cuda/cuda-10.0.130/lib64:/opt/local/stow/gcc-9.3.0/lib64:/opt/local/stow/gcc-9.3.0/lib:/vulcan/scratch/kampta/.local/torch/lib:
++ export LD_LIBRARY_PATH
++ LD_RUN_PATH=/opt/common/cudnn/cudnn-10.0-7.6.5/lib64:/usr/lib64/nvidia:/usr/lib/nvidia:/opt/common/cuda/cuda-10.0.130/lib64:/opt/common/cuda/cuda-10.0.130/lib:/opt/local/stow/gcc-9.3.0/lib64:/opt/local/stow/gcc-9.3.0/lib:/opt/local/stow/isl-0.16.1/lib:/opt/local/stow/cloog-0.18.4/lib:/opt/local/stow/mpc-1.0.3/lib:/opt/local/stow/mpfr-3.1.4/lib:/opt/local/stow/gmp-6.1.1/lib
++ export LD_RUN_PATH
++ LIBRARY_PATH=/opt/common/cudnn/cudnn-10.0-7.6.5/lib64:/usr/lib64/nvidia:/usr/lib/nvidia:/opt/common/cuda/cuda-10.0.130/lib64:/opt/common/cuda/cuda-10.0.130/lib:/opt/local/stow/gcc-9.3.0/lib64:/opt/local/stow/gcc-9.3.0/lib:/opt/local/stow/cloog-0.18.4/lib
++ export LIBRARY_PATH
++ LOADEDMODULES=gmp/6.1.1:mpfr/3.1.4:mpc/1.0.3:ppl/1.2:cloog/0.18.4:dejagnu/1.6:autogen/5.18.7:isl/0.16.1:gcc/9.3.0:cuda/10.0.130:cudnn/v7.6.5
++ export LOADEDMODULES
++ MANPATH=/opt/local/stow/gcc-9.3.0/share/man:/opt/local/stow/autogen-5.18.7/share/man:/opt/local/stow/dejagnu-1.6/share/man:/opt/local/stow/ppl-1.2/share/man:/opt/puppetlabs/puppet/share/man
++ export MANPATH
++ PATH=/opt/common/cuda/cuda-10.0.130/bin:/opt/local/stow/gcc-9.3.0/bin:/opt/local/stow/autogen-5.18.7/bin:/opt/local/stow/dejagnu-1.6/bin:/opt/local/stow/cloog-0.18.4/bin:/opt/local/stow/ppl-1.2/bin:/vulcanscratch/kampta/anaconda/envs/py36/bin:/vulcanscratch/kampta/anaconda/condabin:/vulcan/scratch/kampta/.local/torch/bin:/opt/local/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin
++ export PATH
++ PKG_CONFIG_PATH=/opt/common/cuda/cuda-10.0.130/pkgconfig:/opt/local/stow/isl-0.16.1/lib/pkgconfig:/opt/local/stow/cloog-0.18.4/lib/pkgconfig
++ export PKG_CONFIG_PATH
++ PPL_PATH=/opt/local/stow/ppl-1.2
++ export PPL_PATH
++ _LMFILES_=/opt/local/stow/.modulefiles/gmp/6.1.1:/opt/local/stow/.modulefiles/mpfr/3.1.4:/opt/local/stow/.modulefiles/mpc/1.0.3:/opt/local/stow/.modulefiles/ppl/1.2:/opt/local/stow/.modulefiles/cloog/0.18.4:/opt/local/stow/.modulefiles/dejagnu/1.6:/opt/local/stow/.modulefiles/autogen/5.18.7:/opt/local/stow/.modulefiles/isl/0.16.1:/opt/local/stow/.modulefiles/gcc/9.3.0:/opt/common/.modulefiles/cuda/10.0.130:/opt/common/.modulefiles/cudnn/v7.6.5
++ export _LMFILES_
+ export WORK_DIR=/scratch0/slurm_534990
+ WORK_DIR=/scratch0/slurm_534990
+ export PYTHONPATH=.:
+ PYTHONPATH=.:
+ srun bash -c 'mkdir /scratch0/slurm_534990'
+ srun rsync -a '--exclude=*.out' /scratch0/slurm_534990
drwxrwxr-x              6 2020/11/12 18:29:28 slurm_534990
+ srun bash -c 'cd /scratch0/slurm_534990'
+ srun python -u tools/train_net.py --num-gpus 4 --resume --config-file configs/COCO-InstanceSegmentation/mask_rcnn_r18_FPN_1x.yaml MODEL.MASK_ON True SOLVER.BASE_LR 0.015 SOLVER.WARMUP_ITERS 5000 SOLVER.WARMUP_FACTOR 2e-4 LOTTERY_KEEP_PERCENTAGE 0.6 NUM_ROUNDS 2 OUTPUT_DIR /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_rcnn_r18_fpn_warm5k_lr_0.015_prune_60_late_reset/ LATE_RESET_CKPT /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_0007329.pth MODEL.WEIGHTS /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_final.pth
Command Line Args: Namespace(config_file='configs/COCO-InstanceSegmentation/mask_rcnn_r18_FPN_1x.yaml', dist_url='tcp://127.0.0.1:62778', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['MODEL.MASK_ON', 'True', 'SOLVER.BASE_LR', '0.015', 'SOLVER.WARMUP_ITERS', '5000', 'SOLVER.WARMUP_FACTOR', '2e-4', 'LOTTERY_KEEP_PERCENTAGE', '0.6', 'NUM_ROUNDS', '2', 'OUTPUT_DIR', '/fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_rcnn_r18_fpn_warm5k_lr_0.015_prune_60_late_reset/', 'LATE_RESET_CKPT', '/fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_0007329.pth', 'MODEL.WEIGHTS', '/fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_final.pth'], resume=True)
[32m[11/12 18:29:57 detectron2]: [0mRank of current process: 0. World size: 4
cuobjdump info    : File '/fs/vulcan-projects/pruning_sgirish/prune-det/detectron2/_C.cpython-36m-x86_64-linux-gnu.so' does not contain device code
cuobjdump info    : File '/fs/vulcan-projects/pruning_sgirish/prune-det/detectron2/_C.cpython-36m-x86_64-linux-gnu.so' does not contain device code
cuobjdump info    : File '/fs/vulcan-projects/pruning_sgirish/prune-det/detectron2/_C.cpython-36m-x86_64-linux-gnu.so' does not contain device code
cuobjdump info    : File '/fs/vulcan-projects/pruning_sgirish/prune-det/detectron2/_C.cpython-36m-x86_64-linux-gnu.so' does not contain device code
[32m[11/12 18:30:05 detectron2]: [0mEnvironment info:
----------------------  -------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.10 |Anaconda, Inc.| (default, Mar 25 2020, 23:51:54) [GCC 7.3.0]
numpy                   1.19.2
detectron2              0.2.1 @/fs/vulcan-projects/pruning_sgirish/prune-det/detectron2
Compiler                GCC 9.3
CUDA compiler           not available
detectron2 arch flags   /fs/vulcan-projects/pruning_sgirish/prune-det/detectron2/_C.cpython-36m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.7.0 @/vulcanscratch/kampta/anaconda/envs/py36/lib/python3.6/site-packages/torch
PyTorch debug build     True
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti (arch=6.1)
CUDA_HOME               /opt/common/cuda/cuda-10.0.130
Pillow                  8.0.1
torchvision             0.8.1 @/vulcanscratch/kampta/anaconda/envs/py36/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.2.post20201104
cv2                     4.2.0
----------------------  -------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[32m[11/12 18:30:05 detectron2]: [0mCommand line arguments: Namespace(config_file='configs/COCO-InstanceSegmentation/mask_rcnn_r18_FPN_1x.yaml', dist_url='tcp://127.0.0.1:62778', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['MODEL.MASK_ON', 'True', 'SOLVER.BASE_LR', '0.015', 'SOLVER.WARMUP_ITERS', '5000', 'SOLVER.WARMUP_FACTOR', '2e-4', 'LOTTERY_KEEP_PERCENTAGE', '0.6', 'NUM_ROUNDS', '2', 'OUTPUT_DIR', '/fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_rcnn_r18_fpn_warm5k_lr_0.015_prune_60_late_reset/', 'LATE_RESET_CKPT', '/fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_0007329.pth', 'MODEL.WEIGHTS', '/fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_final.pth'], resume=True)
[32m[11/12 18:30:05 detectron2]: [0mContents of args.config_file=configs/COCO-InstanceSegmentation/mask_rcnn_r18_FPN_1x.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "https://download.pytorch.org/models/resnet18-5c106cde.pth"
  MASK_ON: True
  RESNETS:
    DEPTH: 18
    RES2_OUT_CHANNELS: 64
# DATASETS:
#   TRAIN: ("coco_2017_val",)
#   TEST: ("coco_2017_val",) #("coco_2017_test-dev",)
SOLVER:
  BASE_LR: 0.02
  CHECKPOINT_PERIOD: 7330
  # IMS_PER_BATCH: 24
  # STEPS: (40000, 53500)
  # MAX_ITER: 60000
  # WARMUP_FACTOR: 5e-4
  # WARMUP_ITERS: 2000
OUTPUT_DIR: output/faster_r18_fpn

[32m[11/12 18:30:05 detectron2]: [0mRunning with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('coco_2017_val',)
  TRAIN: ('coco_2017_train',)
GLOBAL:
  HACK: 1.0
IMAGENET_TICKET: 
IMAGENET_TICKET_TYPE: 
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
LATE_RESET_CKPT: /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_0007329.pth
LOTTERY_KEEP_PERCENTAGE: 0.6
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 18
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 64
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_final.pth
NUM_ROUNDS: 2
OUTPUT_DIR: /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_rcnn_r18_fpn_warm5k_lr_0.015_prune_60_late_reset/
PRUNE_RESUME: True
SEED: -1
SOLVER:
  BASE_LR: 0.015
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 7330
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.0002
  WARMUP_ITERS: 5000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[32m[11/12 18:30:05 detectron2]: [0mFull config saved to /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_rcnn_r18_fpn_warm5k_lr_0.015_prune_60_late_reset/config.yaml
[32m[11/12 18:30:05 d2.utils.env]: [0mUsing a generated random seed 5702194
[32m[11/12 18:30:06 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BasicBlock(
          (shortcut): Conv2d(
            64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BasicBlock(
          (shortcut): Conv2d(
            128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BasicBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[11/12 18:30:26 d2.data.datasets.coco]: [0mLoading datasets/coco/annotations/instances_train2017.json takes 20.15 seconds.
[32m[11/12 18:30:27 d2.data.datasets.coco]: [0mLoaded 118287 images in COCO format from datasets/coco/annotations/instances_train2017.json
[32m[11/12 18:30:38 d2.data.build]: [0mRemoved 1021 images with no usable annotations. 117266 images left.
[32m[11/12 18:30:44 d2.data.build]: [0mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 5129         |      bus      | 6061         |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 12842        | fire hydrant | 1865         |   stop sign   | 1983         |
| parking meter | 1283         |    bench     | 9820         |     bird      | 10542        |
|      cat      | 4766         |     dog      | 5500         |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 8014         |   elephant    | 5484         |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 11265        |    handbag    | 12342        |
|      tie      | 6448         |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 2681         |  sports ball  | 6299         |
|     kite      | 8802         | baseball bat | 3273         | baseball gl.. | 3747         |
|  skateboard   | 5536         |  surfboard   | 6095         | tennis racket | 4807         |
|    bottle     | 24070        |  wine glass  | 7839         |      cup      | 20574        |
|     fork      | 5474         |    knife     | 7760         |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 2884         |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 6296         |     chair     | 38073        |
|     couch     | 5779         | potted plant | 8631         |      bed      | 4192         |
| dining table  | 15695        |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 2854         |  cell phone  | 6422         |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 5609         |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 1464         |  teddy bear   | 4729         |
|  hair drier   | 198          |  toothbrush  | 1945         |               |              |
|     total     | 849949       |              |              |               |              |[0m
[32m[11/12 18:30:44 d2.data.common]: [0mSerializing 117266 elements to byte tensors and concatenating them all ...
[32m[11/12 18:30:49 d2.data.common]: [0mSerialized dataset takes 451.21 MiB
[32m[11/12 18:30:49 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[11/12 18:30:49 d2.data.build]: [0mUsing training sampler TrainingSampler
Loaded from  /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_final.pth 

here
Pruning:  backbone.fpn_lateral2.weight
Pruning:  backbone.fpn_output2.weight
Pruning:  backbone.fpn_lateral3.weight
Pruning:  backbone.fpn_output3.weight
Pruning:  backbone.fpn_lateral4.weight
Pruning:  backbone.fpn_output4.weight
Pruning:  backbone.fpn_lateral5.weight
Pruning:  backbone.fpn_output5.weight
Pruning:  backbone.bottom_up.stem.conv1.weight
Pruning:  backbone.bottom_up.res2.0.conv1.weight
Pruning:  backbone.bottom_up.res2.0.conv2.weight
Pruning:  backbone.bottom_up.res2.1.conv1.weight
Pruning:  backbone.bottom_up.res2.1.conv2.weight
Pruning:  backbone.bottom_up.res3.0.conv1.weight
Pruning:  backbone.bottom_up.res3.0.conv2.weight
Pruning:  backbone.bottom_up.res3.1.conv1.weight
Pruning:  backbone.bottom_up.res3.1.conv2.weight
Pruning:  backbone.bottom_up.res4.0.conv1.weight
Pruning:  backbone.bottom_up.res4.0.conv2.weight
Pruning:  backbone.bottom_up.res4.1.conv1.weight
Pruning:  backbone.bottom_up.res4.1.conv2.weight
Pruning:  backbone.bottom_up.res5.0.conv1.weight
Pruning:  backbone.bottom_up.res5.0.conv2.weight
Pruning:  backbone.bottom_up.res5.1.conv1.weight
Pruning:  backbone.bottom_up.res5.1.conv2.weight
Pruning:  proposal_generator.rpn_head.conv.weight
Pruning:  roi_heads.box_head.fc1.weight
Pruning:  roi_heads.box_head.fc2.weight
Pruning:  roi_heads.mask_head.mask_fcn1.weight
Pruning:  roi_heads.mask_head.mask_fcn2.weight
Pruning:  roi_heads.mask_head.mask_fcn3.weight
Pruning:  roi_heads.mask_head.mask_fcn4.weight
Pruning:  roi_heads.mask_head.deconv.weight
generating new mask by pruning
Loading  /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_0007329.pth  late reset to model as initial

applied mask
Pruning:  module.backbone.fpn_lateral2.weight
Pruning:  module.backbone.fpn_output2.weight
Pruning:  module.backbone.fpn_lateral3.weight
Pruning:  module.backbone.fpn_output3.weight
Pruning:  module.backbone.fpn_lateral4.weight
Pruning:  module.backbone.fpn_output4.weight
Pruning:  module.backbone.fpn_lateral5.weight
Pruning:  module.backbone.fpn_output5.weight
Pruning:  module.backbone.bottom_up.stem.conv1.weight
Pruning:  module.backbone.bottom_up.res2.0.conv1.weight
Pruning:  module.backbone.bottom_up.res2.0.conv2.weight
Pruning:  module.backbone.bottom_up.res2.1.conv1.weight
Pruning:  module.backbone.bottom_up.res2.1.conv2.weight
Pruning:  module.backbone.bottom_up.res3.0.conv1.weight
Pruning:  module.backbone.bottom_up.res3.0.conv2.weight
Pruning:  module.backbone.bottom_up.res3.1.conv1.weight
Pruning:  module.backbone.bottom_up.res3.1.conv2.weight
Pruning:  module.backbone.bottom_up.res4.0.conv1.weight
Pruning:  module.backbone.bottom_up.res4.0.conv2.weight
Pruning:  module.backbone.bottom_up.res4.1.conv1.weight
Pruning:  module.backbone.bottom_up.res4.1.conv2.weight
Pruning:  module.backbone.bottom_up.res5.0.conv1.weight
Pruning:  module.backbone.bottom_up.res5.0.conv2.weight
Pruning:  module.backbone.bottom_up.res5.1.conv1.weight
Pruning:  module.backbone.bottom_up.res5.1.conv2.weight
Pruning:  module.proposal_generator.rpn_head.conv.weight
Pruning:  module.roi_heads.box_head.fc1.weight
Pruning:  module.roi_heads.box_head.fc2.weight
Pruning:  module.roi_heads.mask_head.mask_fcn1.weight
Pruning:  module.roi_heads.mask_head.mask_fcn2.weight
Pruning:  module.roi_heads.mask_head.mask_fcn3.weight
Pruning:  module.roi_heads.mask_head.mask_fcn4.weight
Pruning:  module.roi_heads.mask_head.deconv.weight
Zero percentage: 0.3921692987686034
Model zero count:  0.3921692987686034

MODULE WISE param count
Zero percentage: 0.3008201820006598
children:  backbone 0.3008201820006598 13774016
Zero percentage: 0.44513120122572336
children:  proposal_generator 0.44513120122572336 593935
Zero percentage: 0.4645462518108423
children:  roi_heads 0.4645462518108423 16949985



backbone 13774016  percentage of total:  0.406313515911666
proposal_generator 593935  percentage of total:  0.01752022199429675
roi_heads 16949985  percentage of total:  0.5



Transferred ticket part: zeros 
Zero percentage: 0.31827314168049126


Loaded from  /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_final.pth 

here
Pruning:  backbone.fpn_lateral2.weight
Pruning:  backbone.fpn_output2.weight
Pruning:  backbone.fpn_lateral3.weight
Pruning:  backbone.fpn_output3.weight
Pruning:  backbone.fpn_lateral4.weight
Pruning:  backbone.fpn_output4.weight
Pruning:  backbone.fpn_lateral5.weight
Pruning:  backbone.fpn_output5.weight
Pruning:  backbone.bottom_up.stem.conv1.weight
Pruning:  backbone.bottom_up.res2.0.conv1.weight
Pruning:  backbone.bottom_up.res2.0.conv2.weight
Pruning:  backbone.bottom_up.res2.1.conv1.weight
Pruning:  backbone.bottom_up.res2.1.conv2.weight
Pruning:  backbone.bottom_up.res3.0.conv1.weight
Pruning:  backbone.bottom_up.res3.0.conv2.weight
Pruning:  backbone.bottom_up.res3.1.conv1.weight
Pruning:  backbone.bottom_up.res3.1.conv2.weight
Pruning:  backbone.bottom_up.res4.0.conv1.weight
Pruning:  backbone.bottom_up.res4.0.conv2.weight
Pruning:  backbone.bottom_up.res4.1.conv1.weight
Pruning:  backbone.bottom_up.res4.1.conv2.weight
Pruning:  backbone.bottom_up.res5.0.conv1.weight
Pruning:  backbone.bottom_up.res5.0.conv2.weight
Pruning:  backbone.bottom_up.res5.1.conv1.weight
Pruning:  backbone.bottom_up.res5.1.conv2.weight
Pruning:  proposal_generator.rpn_head.conv.weight
Pruning:  roi_heads.box_head.fc1.weight
Pruning:  roi_heads.box_head.fc2.weight
Pruning:  roi_heads.mask_head.mask_fcn1.weight
Pruning:  roi_heads.mask_head.mask_fcn2.weight
Pruning:  roi_heads.mask_head.mask_fcn3.weight
Pruning:  roi_heads.mask_head.mask_fcn4.weight
Pruning:  roi_heads.mask_head.deconv.weight
generating new mask by pruning
Loading  /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_0007329.pth  late reset to model as initial

applied mask
Pruning:  module.backbone.fpn_lateral2.weight
Pruning:  module.backbone.fpn_output2.weight
Pruning:  module.backbone.fpn_lateral3.weight
Pruning:  module.backbone.fpn_output3.weight
Pruning:  module.backbone.fpn_lateral4.weight
Pruning:  module.backbone.fpn_output4.weight
Pruning:  module.backbone.fpn_lateral5.weight
Pruning:  module.backbone.fpn_output5.weight
Pruning:  module.backbone.bottom_up.stem.conv1.weight
Pruning:  module.backbone.bottom_up.res2.0.conv1.weight
Pruning:  module.backbone.bottom_up.res2.0.conv2.weight
Pruning:  module.backbone.bottom_up.res2.1.conv1.weight
Pruning:  module.backbone.bottom_up.res2.1.conv2.weight
Pruning:  module.backbone.bottom_up.res3.0.conv1.weight
Pruning:  module.backbone.bottom_up.res3.0.conv2.weight
Pruning:  module.backbone.bottom_up.res3.1.conv1.weight
Pruning:  module.backbone.bottom_up.res3.1.conv2.weight
Pruning:  module.backbone.bottom_up.res4.0.conv1.weight
Pruning:  module.backbone.bottom_up.res4.0.conv2.weight
Pruning:  module.backbone.bottom_up.res4.1.conv1.weight
Pruning:  module.backbone.bottom_up.res4.1.conv2.weight
Pruning:  module.backbone.bottom_up.res5.0.conv1.weight
Pruning:  module.backbone.bottom_up.res5.0.conv2.weight
Pruning:  module.backbone.bottom_up.res5.1.conv1.weight
Pruning:  module.backbone.bottom_up.res5.1.conv2.weight
Pruning:  module.proposal_generator.rpn_head.conv.weight
Pruning:  module.roi_heads.box_head.fc1.weight
Pruning:  module.roi_heads.box_head.fc2.weight
Pruning:  module.roi_heads.mask_head.mask_fcn1.weight
Pruning:  module.roi_heads.mask_head.mask_fcn2.weight
Pruning:  module.roi_heads.mask_head.mask_fcn3.weight
Pruning:  module.roi_heads.mask_head.mask_fcn4.weight
Pruning:  module.roi_heads.mask_head.deconv.weight
Zero percentage: 0.3921692987686034
Model zero count:  0.3921692987686034

MODULE WISE param count
Zero percentage: 0.3008201820006598
children:  backbone 0.3008201820006598 13774016
Zero percentage: 0.44513120122572336
children:  proposal_generator 0.44513120122572336 593935
Zero percentage: 0.4645462518108423
children:  roi_heads 0.4645462518108423 16949985



backbone 13774016  percentage of total:  0.406313515911666
proposal_generator 593935  percentage of total:  0.01752022199429675
roi_heads 16949985  percentage of total:  0.5



Transferred ticket part: zeros 
Zero percentage: 0.31827314168049126


Loaded from  /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_final.pth 

here
Pruning:  backbone.fpn_lateral2.weight
Pruning:  backbone.fpn_output2.weight
Pruning:  backbone.fpn_lateral3.weight
Pruning:  backbone.fpn_output3.weight
Pruning:  backbone.fpn_lateral4.weight
Pruning:  backbone.fpn_output4.weight
Pruning:  backbone.fpn_lateral5.weight
Pruning:  backbone.fpn_output5.weight
Pruning:  backbone.bottom_up.stem.conv1.weight
Pruning:  backbone.bottom_up.res2.0.conv1.weight
Pruning:  backbone.bottom_up.res2.0.conv2.weight
Pruning:  backbone.bottom_up.res2.1.conv1.weight
Pruning:  backbone.bottom_up.res2.1.conv2.weight
Pruning:  backbone.bottom_up.res3.0.conv1.weight
Pruning:  backbone.bottom_up.res3.0.conv2.weight
Pruning:  backbone.bottom_up.res3.1.conv1.weight
Pruning:  backbone.bottom_up.res3.1.conv2.weight
Pruning:  backbone.bottom_up.res4.0.conv1.weight
Pruning:  backbone.bottom_up.res4.0.conv2.weight
Pruning:  backbone.bottom_up.res4.1.conv1.weight
Pruning:  backbone.bottom_up.res4.1.conv2.weight
Pruning:  backbone.bottom_up.res5.0.conv1.weight
Pruning:  backbone.bottom_up.res5.0.conv2.weight
Pruning:  backbone.bottom_up.res5.1.conv1.weight
Pruning:  backbone.bottom_up.res5.1.conv2.weight
Pruning:  proposal_generator.rpn_head.conv.weight
Pruning:  roi_heads.box_head.fc1.weight
Pruning:  roi_heads.box_head.fc2.weight
Pruning:  roi_heads.mask_head.mask_fcn1.weight
Pruning:  roi_heads.mask_head.mask_fcn2.weight
Pruning:  roi_heads.mask_head.mask_fcn3.weight
Pruning:  roi_heads.mask_head.mask_fcn4.weight
Pruning:  roi_heads.mask_head.deconv.weight
generating new mask by pruning
Loading  /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_0007329.pth  late reset to model as initial

applied mask
Pruning:  module.backbone.fpn_lateral2.weight
Pruning:  module.backbone.fpn_output2.weight
Pruning:  module.backbone.fpn_lateral3.weight
Pruning:  module.backbone.fpn_output3.weight
Pruning:  module.backbone.fpn_lateral4.weight
Pruning:  module.backbone.fpn_output4.weight
Pruning:  module.backbone.fpn_lateral5.weight
Pruning:  module.backbone.fpn_output5.weight
Pruning:  module.backbone.bottom_up.stem.conv1.weight
Pruning:  module.backbone.bottom_up.res2.0.conv1.weight
Pruning:  module.backbone.bottom_up.res2.0.conv2.weight
Pruning:  module.backbone.bottom_up.res2.1.conv1.weight
Pruning:  module.backbone.bottom_up.res2.1.conv2.weight
Pruning:  module.backbone.bottom_up.res3.0.conv1.weight
Pruning:  module.backbone.bottom_up.res3.0.conv2.weight
Pruning:  module.backbone.bottom_up.res3.1.conv1.weight
Pruning:  module.backbone.bottom_up.res3.1.conv2.weight
Pruning:  module.backbone.bottom_up.res4.0.conv1.weight
Pruning:  module.backbone.bottom_up.res4.0.conv2.weight
Pruning:  module.backbone.bottom_up.res4.1.conv1.weight
Pruning:  module.backbone.bottom_up.res4.1.conv2.weight
Pruning:  module.backbone.bottom_up.res5.0.conv1.weight
Pruning:  module.backbone.bottom_up.res5.0.conv2.weight
Pruning:  module.backbone.bottom_up.res5.1.conv1.weight
Pruning:  module.backbone.bottom_up.res5.1.conv2.weight
Pruning:  module.proposal_generator.rpn_head.conv.weight
Pruning:  module.roi_heads.box_head.fc1.weight
Pruning:  module.roi_heads.box_head.fc2.weight
Pruning:  module.roi_heads.mask_head.mask_fcn1.weight
Pruning:  module.roi_heads.mask_head.mask_fcn2.weight
Pruning:  module.roi_heads.mask_head.mask_fcn3.weight
Pruning:  module.roi_heads.mask_head.mask_fcn4.weight
Pruning:  module.roi_heads.mask_head.deconv.weight
Zero percentage: 0.3921692987686034
Model zero count:  0.3921692987686034

MODULE WISE param count
Zero percentage: 0.3008201820006598
children:  backbone 0.3008201820006598 13774016
Zero percentage: 0.44513120122572336
children:  proposal_generator 0.44513120122572336 593935
Zero percentage: 0.4645462518108423
children:  roi_heads 0.4645462518108423 16949985



backbone 13774016  percentage of total:  0.406313515911666
proposal_generator 593935  percentage of total:  0.01752022199429675
roi_heads 16949985  percentage of total:  0.5



Transferred ticket part: zeros 
Zero percentage: 0.31827314168049126


[32m[11/12 18:31:31 fvcore.common.checkpoint]: [0mLoading checkpoint from /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_final.pth
Loaded from  /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_final.pth 

here
Pruning:  backbone.fpn_lateral2.weight
Pruning:  backbone.fpn_output2.weight
Pruning:  backbone.fpn_lateral3.weight
Pruning:  backbone.fpn_output3.weight
Pruning:  backbone.fpn_lateral4.weight
Pruning:  backbone.fpn_output4.weight
Pruning:  backbone.fpn_lateral5.weight
Pruning:  backbone.fpn_output5.weight
Pruning:  backbone.bottom_up.stem.conv1.weight
Pruning:  backbone.bottom_up.res2.0.conv1.weight
Pruning:  backbone.bottom_up.res2.0.conv2.weight
Pruning:  backbone.bottom_up.res2.1.conv1.weight
Pruning:  backbone.bottom_up.res2.1.conv2.weight
Pruning:  backbone.bottom_up.res3.0.conv1.weight
Pruning:  backbone.bottom_up.res3.0.conv2.weight
Pruning:  backbone.bottom_up.res3.1.conv1.weight
Pruning:  backbone.bottom_up.res3.1.conv2.weight
Pruning:  backbone.bottom_up.res4.0.conv1.weight
Pruning:  backbone.bottom_up.res4.0.conv2.weight
Pruning:  backbone.bottom_up.res4.1.conv1.weight
Pruning:  backbone.bottom_up.res4.1.conv2.weight
Pruning:  backbone.bottom_up.res5.0.conv1.weight
Pruning:  backbone.bottom_up.res5.0.conv2.weight
Pruning:  backbone.bottom_up.res5.1.conv1.weight
Pruning:  backbone.bottom_up.res5.1.conv2.weight
Pruning:  proposal_generator.rpn_head.conv.weight
Pruning:  roi_heads.box_head.fc1.weight
Pruning:  roi_heads.box_head.fc2.weight
Pruning:  roi_heads.mask_head.mask_fcn1.weight
Pruning:  roi_heads.mask_head.mask_fcn2.weight
Pruning:  roi_heads.mask_head.mask_fcn3.weight
Pruning:  roi_heads.mask_head.mask_fcn4.weight
Pruning:  roi_heads.mask_head.deconv.weight
generating new mask by pruning
Loading  /fs/vulcan-projects/pruning_sgirish/prune-det/output/mask_r18_fpn_warm5k_lr.015/model_0007329.pth  late reset to model as initial

applied mask
Pruning:  module.backbone.fpn_lateral2.weight
Pruning:  module.backbone.fpn_output2.weight
Pruning:  module.backbone.fpn_lateral3.weight
Pruning:  module.backbone.fpn_output3.weight
Pruning:  module.backbone.fpn_lateral4.weight
Pruning:  module.backbone.fpn_output4.weight
Pruning:  module.backbone.fpn_lateral5.weight
Pruning:  module.backbone.fpn_output5.weight
Pruning:  module.backbone.bottom_up.stem.conv1.weight
Pruning:  module.backbone.bottom_up.res2.0.conv1.weight
Pruning:  module.backbone.bottom_up.res2.0.conv2.weight
Pruning:  module.backbone.bottom_up.res2.1.conv1.weight
Pruning:  module.backbone.bottom_up.res2.1.conv2.weight
Pruning:  module.backbone.bottom_up.res3.0.conv1.weight
Pruning:  module.backbone.bottom_up.res3.0.conv2.weight
Pruning:  module.backbone.bottom_up.res3.1.conv1.weight
Pruning:  module.backbone.bottom_up.res3.1.conv2.weight
Pruning:  module.backbone.bottom_up.res4.0.conv1.weight
Pruning:  module.backbone.bottom_up.res4.0.conv2.weight
Pruning:  module.backbone.bottom_up.res4.1.conv1.weight
Pruning:  module.backbone.bottom_up.res4.1.conv2.weight
Pruning:  module.backbone.bottom_up.res5.0.conv1.weight
Pruning:  module.backbone.bottom_up.res5.0.conv2.weight
Pruning:  module.backbone.bottom_up.res5.1.conv1.weight
Pruning:  module.backbone.bottom_up.res5.1.conv2.weight
Pruning:  module.proposal_generator.rpn_head.conv.weight
Pruning:  module.roi_heads.box_head.fc1.weight
Pruning:  module.roi_heads.box_head.fc2.weight
Pruning:  module.roi_heads.mask_head.mask_fcn1.weight
Pruning:  module.roi_heads.mask_head.mask_fcn2.weight
Pruning:  module.roi_heads.mask_head.mask_fcn3.weight
Pruning:  module.roi_heads.mask_head.mask_fcn4.weight
Pruning:  module.roi_heads.mask_head.deconv.weight
Zero percentage: 0.3921692987686034
Model zero count:  0.3921692987686034

MODULE WISE param count
Zero percentage: 0.3008201820006598
children:  backbone 0.3008201820006598 13774016
Zero percentage: 0.44513120122572336
children:  proposal_generator 0.44513120122572336 593935
Zero percentage: 0.4645462518108423
children:  roi_heads 0.4645462518108423 16949985



backbone 13774016  percentage of total:  0.406313515911666
proposal_generator 593935  percentage of total:  0.01752022199429675
roi_heads 16949985  percentage of total:  0.5



Transferred ticket part: zeros 
Zero percentage: 0.31827314168049126


[32m[11/12 18:31:32 d2.engine.train_loop]: [0mStarting training from iteration 0
/vulcanscratch/kampta/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/vulcanscratch/kampta/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/vulcanscratch/kampta/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/vulcanscratch/kampta/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/vulcanscratch/kampta/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/vulcanscratch/kampta/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
[32m[11/12 18:31:59 d2.utils.events]: [0m eta: 12:45:12  iter: 19  total_loss: 1.134  loss_cls: 0.2815  loss_box_reg: 0.1837  loss_mask: 0.3948  loss_rpn_cls: 0.1439  loss_rpn_loc: 0.1388  time: 0.5136  data_time: 0.8829  lr: 5.9989e-05  max_mem: 3762M
[32m[11/12 18:32:09 d2.utils.events]: [0m eta: 12:52:04  iter: 39  total_loss: 1.106  loss_cls: 0.2819  loss_box_reg: 0.1779  loss_mask: 0.3782  loss_rpn_cls: 0.1411  loss_rpn_loc: 0.1255  time: 0.5169  data_time: 0.0225  lr: 0.00011998  max_mem: 3834M
[32m[11/12 18:32:20 d2.utils.events]: [0m eta: 13:01:03  iter: 59  total_loss: 1.165  loss_cls: 0.3241  loss_box_reg: 0.2182  loss_mask: 0.3817  loss_rpn_cls: 0.1229  loss_rpn_loc: 0.1288  time: 0.5230  data_time: 0.0205  lr: 0.00017996  max_mem: 3834M
[32m[11/12 18:32:32 d2.utils.events]: [0m eta: 13:01:20  iter: 79  total_loss: 1.114  loss_cls: 0.2854  loss_box_reg: 0.2157  loss_mask: 0.3768  loss_rpn_cls: 0.1178  loss_rpn_loc: 0.1099  time: 0.5449  data_time: 0.1072  lr: 0.00023995  max_mem: 3852M
[32m[11/12 18:32:43 d2.utils.events]: [0m eta: 13:10:31  iter: 99  total_loss: 1.173  loss_cls: 0.326  loss_box_reg: 0.2296  loss_mask: 0.3806  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.1133  time: 0.5461  data_time: 0.0199  lr: 0.00029994  max_mem: 4063M
[32m[11/12 18:32:54 d2.utils.events]: [0m eta: 13:19:58  iter: 119  total_loss: 1.212  loss_cls: 0.3411  loss_box_reg: 0.2574  loss_mask: 0.3632  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.142  time: 0.5499  data_time: 0.0194  lr: 0.00035993  max_mem: 4150M
[32m[11/12 18:33:05 d2.utils.events]: [0m eta: 13:23:36  iter: 139  total_loss: 1.2  loss_cls: 0.343  loss_box_reg: 0.2453  loss_mask: 0.3606  loss_rpn_cls: 0.09365  loss_rpn_loc: 0.1295  time: 0.5510  data_time: 0.0241  lr: 0.00041992  max_mem: 4150M
[32m[11/12 18:33:17 d2.utils.events]: [0m eta: 13:30:06  iter: 159  total_loss: 1.159  loss_cls: 0.3204  loss_box_reg: 0.2667  loss_mask: 0.3587  loss_rpn_cls: 0.09745  loss_rpn_loc: 0.1194  time: 0.5535  data_time: 0.0180  lr: 0.0004799  max_mem: 4325M
[32m[11/12 18:33:28 d2.utils.events]: [0m eta: 13:38:40  iter: 179  total_loss: 1.073  loss_cls: 0.3022  loss_box_reg: 0.2406  loss_mask: 0.3623  loss_rpn_cls: 0.0842  loss_rpn_loc: 0.09587  time: 0.5549  data_time: 0.0260  lr: 0.00053989  max_mem: 4325M
[32m[11/12 18:33:40 d2.utils.events]: [0m eta: 13:42:38  iter: 199  total_loss: 1.203  loss_cls: 0.3504  loss_box_reg: 0.2624  loss_mask: 0.3608  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.1094  time: 0.5562  data_time: 0.0181  lr: 0.00059988  max_mem: 4325M
[32m[11/12 18:33:51 d2.utils.events]: [0m eta: 13:46:16  iter: 219  total_loss: 1.201  loss_cls: 0.3404  loss_box_reg: 0.2753  loss_mask: 0.3565  loss_rpn_cls: 0.107  loss_rpn_loc: 0.1184  time: 0.5581  data_time: 0.0209  lr: 0.00065987  max_mem: 4325M
[32m[11/12 18:34:02 d2.utils.events]: [0m eta: 13:45:42  iter: 239  total_loss: 1.15  loss_cls: 0.3124  loss_box_reg: 0.2532  loss_mask: 0.3555  loss_rpn_cls: 0.09571  loss_rpn_loc: 0.1135  time: 0.5579  data_time: 0.0189  lr: 0.00071986  max_mem: 4325M
[32m[11/12 18:34:14 d2.utils.events]: [0m eta: 13:47:37  iter: 259  total_loss: 1.122  loss_cls: 0.3299  loss_box_reg: 0.2538  loss_mask: 0.3581  loss_rpn_cls: 0.08151  loss_rpn_loc: 0.09593  time: 0.5592  data_time: 0.0194  lr: 0.00077984  max_mem: 4325M
[32m[11/12 18:34:25 d2.utils.events]: [0m eta: 13:48:41  iter: 279  total_loss: 1.161  loss_cls: 0.3516  loss_box_reg: 0.2715  loss_mask: 0.355  loss_rpn_cls: 0.08918  loss_rpn_loc: 0.1028  time: 0.5603  data_time: 0.0225  lr: 0.00083983  max_mem: 4325M
[32m[11/12 18:34:37 d2.utils.events]: [0m eta: 13:49:40  iter: 299  total_loss: 1.114  loss_cls: 0.3238  loss_box_reg: 0.2581  loss_mask: 0.3456  loss_rpn_cls: 0.07857  loss_rpn_loc: 0.09115  time: 0.5608  data_time: 0.0190  lr: 0.00089982  max_mem: 4325M
[32m[11/12 18:34:48 d2.utils.events]: [0m eta: 13:51:11  iter: 319  total_loss: 1.124  loss_cls: 0.3209  loss_box_reg: 0.2766  loss_mask: 0.3413  loss_rpn_cls: 0.0896  loss_rpn_loc: 0.1139  time: 0.5613  data_time: 0.0230  lr: 0.00095981  max_mem: 4325M
[32m[11/12 18:35:00 d2.utils.events]: [0m eta: 13:52:35  iter: 339  total_loss: 1.177  loss_cls: 0.3371  loss_box_reg: 0.2843  loss_mask: 0.3578  loss_rpn_cls: 0.09048  loss_rpn_loc: 0.09655  time: 0.5623  data_time: 0.0227  lr: 0.0010198  max_mem: 4325M
[32m[11/12 18:35:11 d2.utils.events]: [0m eta: 13:54:07  iter: 359  total_loss: 1.222  loss_cls: 0.3573  loss_box_reg: 0.2909  loss_mask: 0.3592  loss_rpn_cls: 0.08455  loss_rpn_loc: 0.1154  time: 0.5633  data_time: 0.0215  lr: 0.0010798  max_mem: 4325M
[32m[11/12 18:35:23 d2.utils.events]: [0m eta: 13:54:11  iter: 379  total_loss: 1.121  loss_cls: 0.317  loss_box_reg: 0.2569  loss_mask: 0.3533  loss_rpn_cls: 0.08208  loss_rpn_loc: 0.0908  time: 0.5640  data_time: 0.0206  lr: 0.0011398  max_mem: 4415M
[32m[11/12 18:35:34 d2.utils.events]: [0m eta: 13:54:07  iter: 399  total_loss: 1.135  loss_cls: 0.3406  loss_box_reg: 0.2705  loss_mask: 0.3576  loss_rpn_cls: 0.09419  loss_rpn_loc: 0.1073  time: 0.5645  data_time: 0.0213  lr: 0.0011998  max_mem: 4415M
[32m[11/12 18:35:46 d2.utils.events]: [0m eta: 13:55:48  iter: 419  total_loss: 1.205  loss_cls: 0.3415  loss_box_reg: 0.2855  loss_mask: 0.3535  loss_rpn_cls: 0.09643  loss_rpn_loc: 0.1079  time: 0.5650  data_time: 0.0175  lr: 0.0012597  max_mem: 4415M
[32m[11/12 18:35:57 d2.utils.events]: [0m eta: 13:57:25  iter: 439  total_loss: 1.166  loss_cls: 0.3276  loss_box_reg: 0.2884  loss_mask: 0.3513  loss_rpn_cls: 0.0806  loss_rpn_loc: 0.09887  time: 0.5659  data_time: 0.0210  lr: 0.0013197  max_mem: 4415M
[32m[11/12 18:36:09 d2.utils.events]: [0m eta: 14:00:18  iter: 459  total_loss: 1.156  loss_cls: 0.3589  loss_box_reg: 0.2817  loss_mask: 0.346  loss_rpn_cls: 0.07856  loss_rpn_loc: 0.09087  time: 0.5668  data_time: 0.0225  lr: 0.0013797  max_mem: 4415M
[32m[11/12 18:36:21 d2.utils.events]: [0m eta: 14:01:10  iter: 479  total_loss: 1.158  loss_cls: 0.3434  loss_box_reg: 0.2782  loss_mask: 0.3532  loss_rpn_cls: 0.08792  loss_rpn_loc: 0.09083  time: 0.5675  data_time: 0.0198  lr: 0.0014397  max_mem: 4415M
[32m[11/12 18:36:32 d2.utils.events]: [0m eta: 14:01:33  iter: 499  total_loss: 1.139  loss_cls: 0.3309  loss_box_reg: 0.271  loss_mask: 0.3363  loss_rpn_cls: 0.08601  loss_rpn_loc: 0.09062  time: 0.5681  data_time: 0.0183  lr: 0.0014997  max_mem: 4415M
[32m[11/12 18:36:44 d2.utils.events]: [0m eta: 14:01:10  iter: 519  total_loss: 1.149  loss_cls: 0.3164  loss_box_reg: 0.2724  loss_mask: 0.3495  loss_rpn_cls: 0.08424  loss_rpn_loc: 0.1047  time: 0.5681  data_time: 0.0210  lr: 0.0015597  max_mem: 4415M
[32m[11/12 18:36:55 d2.utils.events]: [0m eta: 14:00:50  iter: 539  total_loss: 1.19  loss_cls: 0.327  loss_box_reg: 0.2835  loss_mask: 0.3665  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.1042  time: 0.5679  data_time: 0.0217  lr: 0.0016197  max_mem: 4415M
[32m[11/12 18:37:07 d2.utils.events]: [0m eta: 14:01:11  iter: 559  total_loss: 1.164  loss_cls: 0.3379  loss_box_reg: 0.2829  loss_mask: 0.3538  loss_rpn_cls: 0.09998  loss_rpn_loc: 0.1119  time: 0.5684  data_time: 0.0166  lr: 0.0016797  max_mem: 4415M
[32m[11/12 18:37:18 d2.utils.events]: [0m eta: 14:01:50  iter: 579  total_loss: 1.125  loss_cls: 0.3187  loss_box_reg: 0.2621  loss_mask: 0.3513  loss_rpn_cls: 0.08822  loss_rpn_loc: 0.1004  time: 0.5687  data_time: 0.0169  lr: 0.0017397  max_mem: 4624M
[32m[11/12 18:37:30 d2.utils.events]: [0m eta: 14:02:33  iter: 599  total_loss: 1.232  loss_cls: 0.352  loss_box_reg: 0.292  loss_mask: 0.3536  loss_rpn_cls: 0.09335  loss_rpn_loc: 0.1094  time: 0.5693  data_time: 0.0232  lr: 0.0017996  max_mem: 4624M
[32m[11/12 18:37:42 d2.utils.events]: [0m eta: 14:01:55  iter: 619  total_loss: 1.184  loss_cls: 0.3557  loss_box_reg: 0.2712  loss_mask: 0.3554  loss_rpn_cls: 0.08371  loss_rpn_loc: 0.1166  time: 0.5694  data_time: 0.0225  lr: 0.0018596  max_mem: 4624M
[32m[11/12 18:37:53 d2.utils.events]: [0m eta: 14:02:10  iter: 639  total_loss: 1.173  loss_cls: 0.327  loss_box_reg: 0.281  loss_mask: 0.3621  loss_rpn_cls: 0.08829  loss_rpn_loc: 0.1003  time: 0.5695  data_time: 0.0209  lr: 0.0019196  max_mem: 4624M
[32m[11/12 18:38:05 d2.utils.events]: [0m eta: 14:02:51  iter: 659  total_loss: 1.115  loss_cls: 0.3215  loss_box_reg: 0.2614  loss_mask: 0.3523  loss_rpn_cls: 0.07831  loss_rpn_loc: 0.08976  time: 0.5697  data_time: 0.0197  lr: 0.0019796  max_mem: 4624M
[32m[11/12 18:38:16 d2.utils.events]: [0m eta: 14:03:28  iter: 679  total_loss: 1.225  loss_cls: 0.3364  loss_box_reg: 0.284  loss_mask: 0.3576  loss_rpn_cls: 0.08652  loss_rpn_loc: 0.1027  time: 0.5698  data_time: 0.0190  lr: 0.0020396  max_mem: 4624M
[32m[11/12 18:38:27 d2.utils.events]: [0m eta: 14:03:17  iter: 699  total_loss: 1.116  loss_cls: 0.3154  loss_box_reg: 0.2659  loss_mask: 0.3557  loss_rpn_cls: 0.08029  loss_rpn_loc: 0.1108  time: 0.5697  data_time: 0.0166  lr: 0.0020996  max_mem: 4624M
[32m[11/12 18:38:39 d2.utils.events]: [0m eta: 14:02:59  iter: 719  total_loss: 1.185  loss_cls: 0.3259  loss_box_reg: 0.2669  loss_mask: 0.3658  loss_rpn_cls: 0.0917  loss_rpn_loc: 0.1065  time: 0.5696  data_time: 0.0197  lr: 0.0021596  max_mem: 4624M
[32m[11/12 18:38:50 d2.utils.events]: [0m eta: 14:02:54  iter: 739  total_loss: 1.115  loss_cls: 0.3228  loss_box_reg: 0.266  loss_mask: 0.3397  loss_rpn_cls: 0.08359  loss_rpn_loc: 0.08341  time: 0.5696  data_time: 0.0172  lr: 0.0022196  max_mem: 4624M
[32m[11/12 18:39:02 d2.utils.events]: [0m eta: 14:03:52  iter: 759  total_loss: 1.166  loss_cls: 0.3258  loss_box_reg: 0.2873  loss_mask: 0.356  loss_rpn_cls: 0.09637  loss_rpn_loc: 0.1195  time: 0.5699  data_time: 0.0186  lr: 0.0022795  max_mem: 4624M
[32m[11/12 18:39:13 d2.utils.events]: [0m eta: 14:03:40  iter: 779  total_loss: 1.126  loss_cls: 0.3164  loss_box_reg: 0.2632  loss_mask: 0.3506  loss_rpn_cls: 0.07835  loss_rpn_loc: 0.08439  time: 0.5701  data_time: 0.0202  lr: 0.0023395  max_mem: 4624M
[32m[11/12 18:39:25 d2.utils.events]: [0m eta: 14:03:39  iter: 799  total_loss: 1.185  loss_cls: 0.3303  loss_box_reg: 0.2882  loss_mask: 0.3615  loss_rpn_cls: 0.09477  loss_rpn_loc: 0.119  time: 0.5705  data_time: 0.0180  lr: 0.0023995  max_mem: 4624M
[32m[11/12 18:39:36 d2.utils.events]: [0m eta: 14:03:10  iter: 819  total_loss: 1.095  loss_cls: 0.3005  loss_box_reg: 0.2431  loss_mask: 0.3598  loss_rpn_cls: 0.08527  loss_rpn_loc: 0.08687  time: 0.5701  data_time: 0.0204  lr: 0.0024595  max_mem: 4624M
[32m[11/12 18:39:48 d2.utils.events]: [0m eta: 14:03:21  iter: 839  total_loss: 1.116  loss_cls: 0.3218  loss_box_reg: 0.268  loss_mask: 0.3423  loss_rpn_cls: 0.08554  loss_rpn_loc: 0.09422  time: 0.5706  data_time: 0.0226  lr: 0.0025195  max_mem: 4624M
[32m[11/12 18:40:00 d2.utils.events]: [0m eta: 14:04:05  iter: 859  total_loss: 1.19  loss_cls: 0.3242  loss_box_reg: 0.2905  loss_mask: 0.3534  loss_rpn_cls: 0.09698  loss_rpn_loc: 0.1007  time: 0.5711  data_time: 0.0187  lr: 0.0025795  max_mem: 4624M
[32m[11/12 18:40:11 d2.utils.events]: [0m eta: 14:04:21  iter: 879  total_loss: 1.108  loss_cls: 0.3108  loss_box_reg: 0.2726  loss_mask: 0.3541  loss_rpn_cls: 0.08766  loss_rpn_loc: 0.09943  time: 0.5713  data_time: 0.0225  lr: 0.0026395  max_mem: 4624M
[32m[11/12 18:40:23 d2.utils.events]: [0m eta: 14:04:26  iter: 899  total_loss: 1.133  loss_cls: 0.32  loss_box_reg: 0.2702  loss_mask: 0.3427  loss_rpn_cls: 0.08947  loss_rpn_loc: 0.1146  time: 0.5714  data_time: 0.0189  lr: 0.0026995  max_mem: 4624M
[32m[11/12 18:40:34 d2.utils.events]: [0m eta: 14:04:15  iter: 919  total_loss: 1.147  loss_cls: 0.324  loss_box_reg: 0.2626  loss_mask: 0.3612  loss_rpn_cls: 0.09072  loss_rpn_loc: 0.09052  time: 0.5715  data_time: 0.0207  lr: 0.0027594  max_mem: 4624M
[32m[11/12 18:40:46 d2.utils.events]: [0m eta: 14:04:01  iter: 939  total_loss: 1.063  loss_cls: 0.3136  loss_box_reg: 0.2568  loss_mask: 0.3549  loss_rpn_cls: 0.07411  loss_rpn_loc: 0.08415  time: 0.5714  data_time: 0.0185  lr: 0.0028194  max_mem: 4624M
[32m[11/12 18:40:58 d2.utils.events]: [0m eta: 14:03:59  iter: 959  total_loss: 1.115  loss_cls: 0.3138  loss_box_reg: 0.2641  loss_mask: 0.3518  loss_rpn_cls: 0.09147  loss_rpn_loc: 0.1108  time: 0.5718  data_time: 0.0178  lr: 0.0028794  max_mem: 4624M
[32m[11/12 18:41:09 d2.utils.events]: [0m eta: 14:04:00  iter: 979  total_loss: 1.136  loss_cls: 0.315  loss_box_reg: 0.2597  loss_mask: 0.3435  loss_rpn_cls: 0.07479  loss_rpn_loc: 0.1003  time: 0.5717  data_time: 0.0208  lr: 0.0029394  max_mem: 4624M
[32m[11/12 18:41:21 d2.utils.events]: [0m eta: 14:04:43  iter: 999  total_loss: 1.072  loss_cls: 0.3038  loss_box_reg: 0.2515  loss_mask: 0.3432  loss_rpn_cls: 0.07985  loss_rpn_loc: 0.08933  time: 0.5720  data_time: 0.0196  lr: 0.0029994  max_mem: 4624M
[32m[11/12 18:41:32 d2.utils.events]: [0m eta: 14:06:59  iter: 1019  total_loss: 1.042  loss_cls: 0.2963  loss_box_reg: 0.2666  loss_mask: 0.3442  loss_rpn_cls: 0.08221  loss_rpn_loc: 0.1016  time: 0.5721  data_time: 0.0182  lr: 0.0030594  max_mem: 4624M
[32m[11/12 18:41:44 d2.utils.events]: [0m eta: 14:07:49  iter: 1039  total_loss: 1.138  loss_cls: 0.3268  loss_box_reg: 0.2814  loss_mask: 0.3604  loss_rpn_cls: 0.07858  loss_rpn_loc: 0.09142  time: 0.5724  data_time: 0.0208  lr: 0.0031194  max_mem: 4624M
[32m[11/12 18:41:56 d2.utils.events]: [0m eta: 14:09:38  iter: 1059  total_loss: 1.167  loss_cls: 0.3091  loss_box_reg: 0.2731  loss_mask: 0.3531  loss_rpn_cls: 0.08026  loss_rpn_loc: 0.1084  time: 0.5726  data_time: 0.0181  lr: 0.0031794  max_mem: 4624M
[32m[11/12 18:42:07 d2.utils.events]: [0m eta: 14:10:14  iter: 1079  total_loss: 1.118  loss_cls: 0.3115  loss_box_reg: 0.2655  loss_mask: 0.3407  loss_rpn_cls: 0.09013  loss_rpn_loc: 0.1011  time: 0.5727  data_time: 0.0189  lr: 0.0032394  max_mem: 4624M
[32m[11/12 18:42:19 d2.utils.events]: [0m eta: 14:12:15  iter: 1099  total_loss: 1.126  loss_cls: 0.3047  loss_box_reg: 0.2557  loss_mask: 0.3419  loss_rpn_cls: 0.0811  loss_rpn_loc: 0.1025  time: 0.5728  data_time: 0.0186  lr: 0.0032993  max_mem: 4624M
[32m[11/12 18:42:31 d2.utils.events]: [0m eta: 14:12:15  iter: 1119  total_loss: 1.119  loss_cls: 0.3322  loss_box_reg: 0.2734  loss_mask: 0.3621  loss_rpn_cls: 0.08425  loss_rpn_loc: 0.09007  time: 0.5731  data_time: 0.0197  lr: 0.0033593  max_mem: 4624M
[32m[11/12 18:42:42 d2.utils.events]: [0m eta: 14:12:34  iter: 1139  total_loss: 1.14  loss_cls: 0.3248  loss_box_reg: 0.2728  loss_mask: 0.3434  loss_rpn_cls: 0.08474  loss_rpn_loc: 0.1101  time: 0.5734  data_time: 0.0207  lr: 0.0034193  max_mem: 4624M
[32m[11/12 18:42:54 d2.utils.events]: [0m eta: 14:13:03  iter: 1159  total_loss: 1.152  loss_cls: 0.3304  loss_box_reg: 0.2869  loss_mask: 0.3541  loss_rpn_cls: 0.08008  loss_rpn_loc: 0.09874  time: 0.5737  data_time: 0.0197  lr: 0.0034793  max_mem: 4624M
[32m[11/12 18:43:06 d2.utils.events]: [0m eta: 14:13:13  iter: 1179  total_loss: 1.124  loss_cls: 0.3012  loss_box_reg: 0.2695  loss_mask: 0.3466  loss_rpn_cls: 0.08669  loss_rpn_loc: 0.1044  time: 0.5738  data_time: 0.0190  lr: 0.0035393  max_mem: 4624M
[32m[11/12 18:43:18 d2.utils.events]: [0m eta: 14:13:30  iter: 1199  total_loss: 1.124  loss_cls: 0.3068  loss_box_reg: 0.2687  loss_mask: 0.3345  loss_rpn_cls: 0.08487  loss_rpn_loc: 0.1053  time: 0.5739  data_time: 0.0225  lr: 0.0035993  max_mem: 4624M
[32m[11/12 18:43:29 d2.utils.events]: [0m eta: 14:13:15  iter: 1219  total_loss: 1.109  loss_cls: 0.3231  loss_box_reg: 0.2532  loss_mask: 0.3404  loss_rpn_cls: 0.08127  loss_rpn_loc: 0.09233  time: 0.5740  data_time: 0.0179  lr: 0.0036593  max_mem: 4624M
[32m[11/12 18:43:41 d2.utils.events]: [0m eta: 14:13:48  iter: 1239  total_loss: 1.165  loss_cls: 0.3244  loss_box_reg: 0.2691  loss_mask: 0.3518  loss_rpn_cls: 0.08512  loss_rpn_loc: 0.1029  time: 0.5741  data_time: 0.0200  lr: 0.0037193  max_mem: 4624M
[32m[11/12 18:43:52 d2.utils.events]: [0m eta: 14:14:13  iter: 1259  total_loss: 1.128  loss_cls: 0.3192  loss_box_reg: 0.2786  loss_mask: 0.3522  loss_rpn_cls: 0.08947  loss_rpn_loc: 0.1072  time: 0.5743  data_time: 0.0222  lr: 0.0037792  max_mem: 4624M
[32m[11/12 18:44:04 d2.utils.events]: [0m eta: 14:14:14  iter: 1279  total_loss: 1.192  loss_cls: 0.3215  loss_box_reg: 0.2803  loss_mask: 0.335  loss_rpn_cls: 0.09264  loss_rpn_loc: 0.09603  time: 0.5743  data_time: 0.0195  lr: 0.0038392  max_mem: 4624M
[32m[11/12 18:44:15 d2.utils.events]: [0m eta: 14:14:26  iter: 1299  total_loss: 1.125  loss_cls: 0.3149  loss_box_reg: 0.2725  loss_mask: 0.3457  loss_rpn_cls: 0.08989  loss_rpn_loc: 0.1013  time: 0.5743  data_time: 0.0207  lr: 0.0038992  max_mem: 4624M
[32m[11/12 18:44:27 d2.utils.events]: [0m eta: 14:14:14  iter: 1319  total_loss: 1.075  loss_cls: 0.2944  loss_box_reg: 0.2606  loss_mask: 0.3482  loss_rpn_cls: 0.08045  loss_rpn_loc: 0.09865  time: 0.5743  data_time: 0.0190  lr: 0.0039592  max_mem: 4624M
[32m[11/12 18:44:39 d2.utils.events]: [0m eta: 14:14:30  iter: 1339  total_loss: 1.139  loss_cls: 0.3154  loss_box_reg: 0.2755  loss_mask: 0.3489  loss_rpn_cls: 0.09934  loss_rpn_loc: 0.1156  time: 0.5744  data_time: 0.0190  lr: 0.0040192  max_mem: 4624M
[32m[11/12 18:44:50 d2.utils.events]: [0m eta: 14:14:26  iter: 1359  total_loss: 1.186  loss_cls: 0.3449  loss_box_reg: 0.2848  loss_mask: 0.3495  loss_rpn_cls: 0.08617  loss_rpn_loc: 0.1102  time: 0.5746  data_time: 0.0202  lr: 0.0040792  max_mem: 4624M
[32m[11/12 18:45:02 d2.utils.events]: [0m eta: 14:14:22  iter: 1379  total_loss: 1.114  loss_cls: 0.3195  loss_box_reg: 0.2675  loss_mask: 0.3406  loss_rpn_cls: 0.07277  loss_rpn_loc: 0.07375  time: 0.5748  data_time: 0.0189  lr: 0.0041392  max_mem: 4624M
[32m[11/12 18:45:14 d2.utils.events]: [0m eta: 14:14:11  iter: 1399  total_loss: 1.057  loss_cls: 0.2948  loss_box_reg: 0.2533  loss_mask: 0.3356  loss_rpn_cls: 0.0733  loss_rpn_loc: 0.08929  time: 0.5747  data_time: 0.0197  lr: 0.0041992  max_mem: 4624M
[32m[11/12 18:45:25 d2.utils.events]: [0m eta: 14:13:59  iter: 1419  total_loss: 1.13  loss_cls: 0.322  loss_box_reg: 0.2739  loss_mask: 0.3547  loss_rpn_cls: 0.06505  loss_rpn_loc: 0.09805  time: 0.5748  data_time: 0.0222  lr: 0.0042591  max_mem: 4624M
[32m[11/12 18:45:37 d2.utils.events]: [0m eta: 14:13:53  iter: 1439  total_loss: 1.217  loss_cls: 0.3203  loss_box_reg: 0.2851  loss_mask: 0.354  loss_rpn_cls: 0.09364  loss_rpn_loc: 0.1154  time: 0.5749  data_time: 0.0165  lr: 0.0043191  max_mem: 4624M
[32m[11/12 18:45:48 d2.utils.events]: [0m eta: 14:13:49  iter: 1459  total_loss: 1.111  loss_cls: 0.2983  loss_box_reg: 0.2478  loss_mask: 0.338  loss_rpn_cls: 0.0809  loss_rpn_loc: 0.08521  time: 0.5750  data_time: 0.0204  lr: 0.0043791  max_mem: 4624M
[32m[11/12 18:46:00 d2.utils.events]: [0m eta: 14:13:23  iter: 1479  total_loss: 1.124  loss_cls: 0.2977  loss_box_reg: 0.2588  loss_mask: 0.3515  loss_rpn_cls: 0.09353  loss_rpn_loc: 0.1003  time: 0.5748  data_time: 0.0169  lr: 0.0044391  max_mem: 4624M
[32m[11/12 18:46:11 d2.utils.events]: [0m eta: 14:12:28  iter: 1499  total_loss: 1.091  loss_cls: 0.3152  loss_box_reg: 0.2613  loss_mask: 0.3399  loss_rpn_cls: 0.07449  loss_rpn_loc: 0.09143  time: 0.5748  data_time: 0.0178  lr: 0.0044991  max_mem: 4624M
[32m[11/12 18:46:23 d2.utils.events]: [0m eta: 14:12:30  iter: 1519  total_loss: 1.125  loss_cls: 0.3234  loss_box_reg: 0.275  loss_mask: 0.3426  loss_rpn_cls: 0.08496  loss_rpn_loc: 0.09744  time: 0.5748  data_time: 0.0210  lr: 0.0045591  max_mem: 4624M
[32m[11/12 18:46:34 d2.utils.events]: [0m eta: 14:12:35  iter: 1539  total_loss: 1.148  loss_cls: 0.3219  loss_box_reg: 0.2856  loss_mask: 0.3613  loss_rpn_cls: 0.08473  loss_rpn_loc: 0.1077  time: 0.5748  data_time: 0.0206  lr: 0.0046191  max_mem: 4624M
[32m[11/12 18:46:46 d2.utils.events]: [0m eta: 14:11:28  iter: 1559  total_loss: 1.117  loss_cls: 0.301  loss_box_reg: 0.2764  loss_mask: 0.3438  loss_rpn_cls: 0.08838  loss_rpn_loc: 0.1027  time: 0.5748  data_time: 0.0231  lr: 0.0046791  max_mem: 4624M
[32m[11/12 18:46:57 d2.utils.events]: [0m eta: 14:11:16  iter: 1579  total_loss: 1.153  loss_cls: 0.3293  loss_box_reg: 0.2796  loss_mask: 0.3415  loss_rpn_cls: 0.08067  loss_rpn_loc: 0.09332  time: 0.5749  data_time: 0.0164  lr: 0.0047391  max_mem: 4624M
[32m[11/12 18:47:09 d2.utils.events]: [0m eta: 14:10:10  iter: 1599  total_loss: 1.137  loss_cls: 0.325  loss_box_reg: 0.2816  loss_mask: 0.3391  loss_rpn_cls: 0.08315  loss_rpn_loc: 0.1038  time: 0.5750  data_time: 0.0176  lr: 0.004799  max_mem: 4624M
[32m[11/12 18:47:21 d2.utils.events]: [0m eta: 14:10:32  iter: 1619  total_loss: 1.16  loss_cls: 0.3474  loss_box_reg: 0.2874  loss_mask: 0.3434  loss_rpn_cls: 0.08506  loss_rpn_loc: 0.1101  time: 0.5751  data_time: 0.0191  lr: 0.004859  max_mem: 4624M
[32m[11/12 18:47:32 d2.utils.events]: [0m eta: 14:10:41  iter: 1639  total_loss: 1.134  loss_cls: 0.3133  loss_box_reg: 0.2885  loss_mask: 0.3524  loss_rpn_cls: 0.09044  loss_rpn_loc: 0.1034  time: 0.5752  data_time: 0.0220  lr: 0.004919  max_mem: 4624M
[32m[11/12 18:47:44 d2.utils.events]: [0m eta: 14:09:49  iter: 1659  total_loss: 1.138  loss_cls: 0.3278  loss_box_reg: 0.28  loss_mask: 0.3444  loss_rpn_cls: 0.08251  loss_rpn_loc: 0.09427  time: 0.5752  data_time: 0.0208  lr: 0.004979  max_mem: 4624M
[32m[11/12 18:47:56 d2.utils.events]: [0m eta: 14:09:37  iter: 1679  total_loss: 1.152  loss_cls: 0.3121  loss_box_reg: 0.2689  loss_mask: 0.3471  loss_rpn_cls: 0.08088  loss_rpn_loc: 0.1003  time: 0.5754  data_time: 0.0186  lr: 0.005039  max_mem: 4624M
[32m[11/12 18:48:07 d2.utils.events]: [0m eta: 14:09:21  iter: 1699  total_loss: 1.078  loss_cls: 0.3027  loss_box_reg: 0.2527  loss_mask: 0.3393  loss_rpn_cls: 0.08278  loss_rpn_loc: 0.09066  time: 0.5753  data_time: 0.0210  lr: 0.005099  max_mem: 4624M
[32m[11/12 18:48:19 d2.utils.events]: [0m eta: 14:09:34  iter: 1719  total_loss: 1.15  loss_cls: 0.3338  loss_box_reg: 0.2779  loss_mask: 0.356  loss_rpn_cls: 0.07561  loss_rpn_loc: 0.09557  time: 0.5753  data_time: 0.0174  lr: 0.005159  max_mem: 4624M
[32m[11/12 18:48:30 d2.utils.events]: [0m eta: 14:08:59  iter: 1739  total_loss: 1.067  loss_cls: 0.2861  loss_box_reg: 0.253  loss_mask: 0.3467  loss_rpn_cls: 0.08004  loss_rpn_loc: 0.09011  time: 0.5752  data_time: 0.0199  lr: 0.005219  max_mem: 4624M
[32m[11/12 18:48:41 d2.utils.events]: [0m eta: 14:08:29  iter: 1759  total_loss: 1.139  loss_cls: 0.3301  loss_box_reg: 0.2612  loss_mask: 0.3469  loss_rpn_cls: 0.08457  loss_rpn_loc: 0.1046  time: 0.5752  data_time: 0.0187  lr: 0.0052789  max_mem: 4624M
[32m[11/12 18:48:53 d2.utils.events]: [0m eta: 14:08:35  iter: 1779  total_loss: 1.119  loss_cls: 0.3104  loss_box_reg: 0.2686  loss_mask: 0.3362  loss_rpn_cls: 0.07243  loss_rpn_loc: 0.09525  time: 0.5753  data_time: 0.0229  lr: 0.0053389  max_mem: 4624M
[32m[11/12 18:49:05 d2.utils.events]: [0m eta: 14:08:14  iter: 1799  total_loss: 1.066  loss_cls: 0.3043  loss_box_reg: 0.2536  loss_mask: 0.3288  loss_rpn_cls: 0.07936  loss_rpn_loc: 0.09691  time: 0.5753  data_time: 0.0186  lr: 0.0053989  max_mem: 4624M
[32m[11/12 18:49:16 d2.utils.events]: [0m eta: 14:08:54  iter: 1819  total_loss: 1.135  loss_cls: 0.3184  loss_box_reg: 0.2774  loss_mask: 0.346  loss_rpn_cls: 0.08416  loss_rpn_loc: 0.09671  time: 0.5753  data_time: 0.0226  lr: 0.0054589  max_mem: 4624M
[32m[11/12 18:49:28 d2.utils.events]: [0m eta: 14:09:03  iter: 1839  total_loss: 1.182  loss_cls: 0.3271  loss_box_reg: 0.2667  loss_mask: 0.3485  loss_rpn_cls: 0.08505  loss_rpn_loc: 0.1017  time: 0.5754  data_time: 0.0211  lr: 0.0055189  max_mem: 4624M
[32m[11/12 18:49:40 d2.utils.events]: [0m eta: 14:08:26  iter: 1859  total_loss: 1.065  loss_cls: 0.3006  loss_box_reg: 0.2574  loss_mask: 0.3562  loss_rpn_cls: 0.07701  loss_rpn_loc: 0.09869  time: 0.5755  data_time: 0.0232  lr: 0.0055789  max_mem: 4624M
[32m[11/12 18:49:51 d2.utils.events]: [0m eta: 14:08:20  iter: 1879  total_loss: 1.152  loss_cls: 0.3091  loss_box_reg: 0.2711  loss_mask: 0.3536  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.09852  time: 0.5755  data_time: 0.0209  lr: 0.0056389  max_mem: 4624M
[32m[11/12 18:50:03 d2.utils.events]: [0m eta: 14:08:35  iter: 1899  total_loss: 1.132  loss_cls: 0.3013  loss_box_reg: 0.265  loss_mask: 0.3401  loss_rpn_cls: 0.08512  loss_rpn_loc: 0.1059  time: 0.5756  data_time: 0.0226  lr: 0.0056989  max_mem: 4624M
[32m[11/12 18:50:14 d2.utils.events]: [0m eta: 14:08:23  iter: 1919  total_loss: 1.103  loss_cls: 0.3053  loss_box_reg: 0.2729  loss_mask: 0.353  loss_rpn_cls: 0.08173  loss_rpn_loc: 0.09584  time: 0.5756  data_time: 0.0179  lr: 0.0057588  max_mem: 4624M
[32m[11/12 18:50:26 d2.utils.events]: [0m eta: 14:08:49  iter: 1939  total_loss: 1.045  loss_cls: 0.2823  loss_box_reg: 0.2462  loss_mask: 0.3326  loss_rpn_cls: 0.07637  loss_rpn_loc: 0.08789  time: 0.5756  data_time: 0.0175  lr: 0.0058188  max_mem: 4624M
[32m[11/12 18:50:37 d2.utils.events]: [0m eta: 14:08:27  iter: 1959  total_loss: 1.12  loss_cls: 0.2993  loss_box_reg: 0.2574  loss_mask: 0.3394  loss_rpn_cls: 0.08566  loss_rpn_loc: 0.1045  time: 0.5756  data_time: 0.0210  lr: 0.0058788  max_mem: 4624M
[32m[11/12 18:50:49 d2.utils.events]: [0m eta: 14:08:49  iter: 1979  total_loss: 1.144  loss_cls: 0.3214  loss_box_reg: 0.284  loss_mask: 0.3534  loss_rpn_cls: 0.08423  loss_rpn_loc: 0.0993  time: 0.5758  data_time: 0.0210  lr: 0.0059388  max_mem: 4624M
[32m[11/12 18:51:01 d2.utils.events]: [0m eta: 14:08:31  iter: 1999  total_loss: 1.122  loss_cls: 0.3224  loss_box_reg: 0.2669  loss_mask: 0.3462  loss_rpn_cls: 0.08716  loss_rpn_loc: 0.1139  time: 0.5758  data_time: 0.0179  lr: 0.0059988  max_mem: 4624M
[32m[11/12 18:51:12 d2.utils.events]: [0m eta: 14:07:52  iter: 2019  total_loss: 1.129  loss_cls: 0.3172  loss_box_reg: 0.2694  loss_mask: 0.3538  loss_rpn_cls: 0.08328  loss_rpn_loc: 0.1057  time: 0.5758  data_time: 0.0167  lr: 0.0060588  max_mem: 4624M
[32m[11/12 18:51:24 d2.utils.events]: [0m eta: 14:06:58  iter: 2039  total_loss: 1.134  loss_cls: 0.315  loss_box_reg: 0.2684  loss_mask: 0.3499  loss_rpn_cls: 0.09076  loss_rpn_loc: 0.09838  time: 0.5758  data_time: 0.0187  lr: 0.0061188  max_mem: 4624M
[32m[11/12 18:51:35 d2.utils.events]: [0m eta: 14:06:12  iter: 2059  total_loss: 1.125  loss_cls: 0.3041  loss_box_reg: 0.2757  loss_mask: 0.3404  loss_rpn_cls: 0.07151  loss_rpn_loc: 0.1059  time: 0.5758  data_time: 0.0210  lr: 0.0061788  max_mem: 4624M
[32m[11/12 18:51:47 d2.utils.events]: [0m eta: 14:06:10  iter: 2079  total_loss: 1.129  loss_cls: 0.3155  loss_box_reg: 0.2638  loss_mask: 0.3396  loss_rpn_cls: 0.08001  loss_rpn_loc: 0.09992  time: 0.5759  data_time: 0.0182  lr: 0.0062388  max_mem: 4624M
[32m[11/12 18:51:59 d2.utils.events]: [0m eta: 14:05:07  iter: 2099  total_loss: 1.08  loss_cls: 0.3018  loss_box_reg: 0.2548  loss_mask: 0.3439  loss_rpn_cls: 0.08341  loss_rpn_loc: 0.1008  time: 0.5759  data_time: 0.0192  lr: 0.0062987  max_mem: 4624M
[32m[11/12 18:52:11 d2.utils.events]: [0m eta: 14:04:55  iter: 2119  total_loss: 1.102  loss_cls: 0.3025  loss_box_reg: 0.2714  loss_mask: 0.3441  loss_rpn_cls: 0.07639  loss_rpn_loc: 0.09819  time: 0.5761  data_time: 0.0460  lr: 0.0063587  max_mem: 4624M
[32m[11/12 18:52:23 d2.utils.events]: [0m eta: 14:05:07  iter: 2139  total_loss: 1.095  loss_cls: 0.3155  loss_box_reg: 0.2628  loss_mask: 0.347  loss_rpn_cls: 0.08693  loss_rpn_loc: 0.09988  time: 0.5763  data_time: 0.0266  lr: 0.0064187  max_mem: 4624M
[32m[11/12 18:52:34 d2.utils.events]: [0m eta: 14:04:22  iter: 2159  total_loss: 1.136  loss_cls: 0.3123  loss_box_reg: 0.2664  loss_mask: 0.3529  loss_rpn_cls: 0.08907  loss_rpn_loc: 0.1117  time: 0.5762  data_time: 0.0211  lr: 0.0064787  max_mem: 4624M
[32m[11/12 18:52:46 d2.utils.events]: [0m eta: 14:04:21  iter: 2179  total_loss: 1.24  loss_cls: 0.3428  loss_box_reg: 0.2922  loss_mask: 0.3618  loss_rpn_cls: 0.09173  loss_rpn_loc: 0.1168  time: 0.5764  data_time: 0.0178  lr: 0.0065387  max_mem: 4624M
[32m[11/12 18:52:57 d2.utils.events]: [0m eta: 14:03:55  iter: 2199  total_loss: 1.093  loss_cls: 0.3009  loss_box_reg: 0.2706  loss_mask: 0.3569  loss_rpn_cls: 0.08336  loss_rpn_loc: 0.09423  time: 0.5763  data_time: 0.0172  lr: 0.0065987  max_mem: 4624M
[32m[11/12 18:53:09 d2.utils.events]: [0m eta: 14:04:02  iter: 2219  total_loss: 1.171  loss_cls: 0.3099  loss_box_reg: 0.2722  loss_mask: 0.3507  loss_rpn_cls: 0.08845  loss_rpn_loc: 0.1203  time: 0.5764  data_time: 0.0215  lr: 0.0066587  max_mem: 4624M
[32m[11/12 18:53:21 d2.utils.events]: [0m eta: 14:03:36  iter: 2239  total_loss: 1.085  loss_cls: 0.3271  loss_box_reg: 0.2608  loss_mask: 0.3382  loss_rpn_cls: 0.08105  loss_rpn_loc: 0.1154  time: 0.5765  data_time: 0.0176  lr: 0.0067187  max_mem: 4624M
[32m[11/12 18:53:32 d2.utils.events]: [0m eta: 14:03:21  iter: 2259  total_loss: 1.091  loss_cls: 0.3005  loss_box_reg: 0.2553  loss_mask: 0.3365  loss_rpn_cls: 0.07639  loss_rpn_loc: 0.08599  time: 0.5765  data_time: 0.0176  lr: 0.0067786  max_mem: 4624M
[32m[11/12 18:53:44 d2.utils.events]: [0m eta: 14:03:20  iter: 2279  total_loss: 1.164  loss_cls: 0.3202  loss_box_reg: 0.2667  loss_mask: 0.3495  loss_rpn_cls: 0.09345  loss_rpn_loc: 0.1117  time: 0.5765  data_time: 0.0197  lr: 0.0068386  max_mem: 4624M
[32m[11/12 18:53:55 d2.utils.events]: [0m eta: 14:03:01  iter: 2299  total_loss: 1.17  loss_cls: 0.3361  loss_box_reg: 0.2844  loss_mask: 0.3415  loss_rpn_cls: 0.07771  loss_rpn_loc: 0.1054  time: 0.5766  data_time: 0.0201  lr: 0.0068986  max_mem: 4624M
[32m[11/12 18:54:07 d2.utils.events]: [0m eta: 14:03:05  iter: 2319  total_loss: 1.118  loss_cls: 0.3176  loss_box_reg: 0.275  loss_mask: 0.3421  loss_rpn_cls: 0.08985  loss_rpn_loc: 0.1178  time: 0.5765  data_time: 0.0196  lr: 0.0069586  max_mem: 4624M
[32m[11/12 18:54:19 d2.utils.events]: [0m eta: 14:02:53  iter: 2339  total_loss: 1.165  loss_cls: 0.3282  loss_box_reg: 0.2874  loss_mask: 0.3552  loss_rpn_cls: 0.08774  loss_rpn_loc: 0.0942  time: 0.5767  data_time: 0.0203  lr: 0.0070186  max_mem: 4624M
[32m[11/12 18:54:30 d2.utils.events]: [0m eta: 14:02:57  iter: 2359  total_loss: 1.122  loss_cls: 0.3161  loss_box_reg: 0.2776  loss_mask: 0.3439  loss_rpn_cls: 0.08749  loss_rpn_loc: 0.09676  time: 0.5767  data_time: 0.0206  lr: 0.0070786  max_mem: 4624M
[32m[11/12 18:54:42 d2.utils.events]: [0m eta: 14:02:30  iter: 2379  total_loss: 1.13  loss_cls: 0.3135  loss_box_reg: 0.2654  loss_mask: 0.345  loss_rpn_cls: 0.08201  loss_rpn_loc: 0.09457  time: 0.5767  data_time: 0.0204  lr: 0.0071386  max_mem: 4624M
[32m[11/12 18:54:54 d2.utils.events]: [0m eta: 14:02:38  iter: 2399  total_loss: 1.145  loss_cls: 0.3294  loss_box_reg: 0.2833  loss_mask: 0.343  loss_rpn_cls: 0.08584  loss_rpn_loc: 0.1062  time: 0.5768  data_time: 0.0189  lr: 0.0071986  max_mem: 4624M
[32m[11/12 18:55:06 d2.utils.events]: [0m eta: 14:02:23  iter: 2419  total_loss: 1.056  loss_cls: 0.295  loss_box_reg: 0.2571  loss_mask: 0.332  loss_rpn_cls: 0.09198  loss_rpn_loc: 0.1126  time: 0.5769  data_time: 0.0204  lr: 0.0072585  max_mem: 4624M
[32m[11/12 18:55:17 d2.utils.events]: [0m eta: 14:01:48  iter: 2439  total_loss: 1.067  loss_cls: 0.2923  loss_box_reg: 0.2619  loss_mask: 0.3414  loss_rpn_cls: 0.07459  loss_rpn_loc: 0.08478  time: 0.5769  data_time: 0.0181  lr: 0.0073185  max_mem: 4624M
[32m[11/12 18:55:28 d2.utils.events]: [0m eta: 14:01:25  iter: 2459  total_loss: 1.085  loss_cls: 0.3102  loss_box_reg: 0.2575  loss_mask: 0.3436  loss_rpn_cls: 0.0767  loss_rpn_loc: 0.09103  time: 0.5768  data_time: 0.0158  lr: 0.0073785  max_mem: 4624M
[32m[11/12 18:55:40 d2.utils.events]: [0m eta: 14:01:16  iter: 2479  total_loss: 1.146  loss_cls: 0.2996  loss_box_reg: 0.277  loss_mask: 0.3472  loss_rpn_cls: 0.09496  loss_rpn_loc: 0.1057  time: 0.5769  data_time: 0.0161  lr: 0.0074385  max_mem: 4624M
[32m[11/12 18:55:51 d2.utils.events]: [0m eta: 14:01:07  iter: 2499  total_loss: 1.175  loss_cls: 0.3186  loss_box_reg: 0.2741  loss_mask: 0.354  loss_rpn_cls: 0.09445  loss_rpn_loc: 0.1046  time: 0.5768  data_time: 0.0178  lr: 0.0074985  max_mem: 4624M
[32m[11/12 18:56:03 d2.utils.events]: [0m eta: 14:01:17  iter: 2519  total_loss: 1.114  loss_cls: 0.3073  loss_box_reg: 0.2558  loss_mask: 0.3489  loss_rpn_cls: 0.09812  loss_rpn_loc: 0.1148  time: 0.5768  data_time: 0.0161  lr: 0.0075585  max_mem: 4624M
[32m[11/12 18:56:15 d2.utils.events]: [0m eta: 14:01:13  iter: 2539  total_loss: 1.148  loss_cls: 0.3064  loss_box_reg: 0.2599  loss_mask: 0.3524  loss_rpn_cls: 0.09052  loss_rpn_loc: 0.1033  time: 0.5769  data_time: 0.0184  lr: 0.0076185  max_mem: 4624M
[32m[11/12 18:56:36 d2.utils.events]: [0m eta: 14:01:13  iter: 2559  total_loss: 1.124  loss_cls: 0.3328  loss_box_reg: 0.2551  loss_mask: 0.3371  loss_rpn_cls: 0.08972  loss_rpn_loc: 0.09828  time: 0.5806  data_time: 0.4836  lr: 0.0076785  max_mem: 4624M
[32m[11/12 18:56:47 d2.utils.events]: [0m eta: 14:00:47  iter: 2579  total_loss: 1.061  loss_cls: 0.2765  loss_box_reg: 0.246  loss_mask: 0.3516  loss_rpn_cls: 0.08106  loss_rpn_loc: 0.09453  time: 0.5805  data_time: 0.0197  lr: 0.0077385  max_mem: 4624M
[32m[11/12 18:56:59 d2.utils.events]: [0m eta: 14:01:04  iter: 2599  total_loss: 1.191  loss_cls: 0.3285  loss_box_reg: 0.2829  loss_mask: 0.3482  loss_rpn_cls: 0.0964  loss_rpn_loc: 0.1243  time: 0.5806  data_time: 0.0183  lr: 0.0077984  max_mem: 4624M
[32m[11/12 18:57:11 d2.utils.events]: [0m eta: 14:00:38  iter: 2619  total_loss: 1.132  loss_cls: 0.3096  loss_box_reg: 0.277  loss_mask: 0.3457  loss_rpn_cls: 0.08277  loss_rpn_loc: 0.1041  time: 0.5805  data_time: 0.0205  lr: 0.0078584  max_mem: 4624M
[32m[11/12 18:57:22 d2.utils.events]: [0m eta: 14:00:27  iter: 2639  total_loss: 1.125  loss_cls: 0.3177  loss_box_reg: 0.2791  loss_mask: 0.3479  loss_rpn_cls: 0.0815  loss_rpn_loc: 0.09455  time: 0.5804  data_time: 0.0175  lr: 0.0079184  max_mem: 4624M
[32m[11/12 18:57:34 d2.utils.events]: [0m eta: 14:00:56  iter: 2659  total_loss: 1.164  loss_cls: 0.3238  loss_box_reg: 0.2831  loss_mask: 0.3502  loss_rpn_cls: 0.07956  loss_rpn_loc: 0.09878  time: 0.5806  data_time: 0.0176  lr: 0.0079784  max_mem: 4624M
[32m[11/12 18:57:46 d2.utils.events]: [0m eta: 14:00:37  iter: 2679  total_loss: 1.079  loss_cls: 0.3038  loss_box_reg: 0.264  loss_mask: 0.3411  loss_rpn_cls: 0.08334  loss_rpn_loc: 0.103  time: 0.5807  data_time: 0.0192  lr: 0.0080384  max_mem: 4624M
[32m[11/12 18:57:57 d2.utils.events]: [0m eta: 14:00:45  iter: 2699  total_loss: 1.141  loss_cls: 0.3193  loss_box_reg: 0.2623  loss_mask: 0.3465  loss_rpn_cls: 0.07791  loss_rpn_loc: 0.1097  time: 0.5807  data_time: 0.0190  lr: 0.0080984  max_mem: 4624M
[32m[11/12 18:58:09 d2.utils.events]: [0m eta: 14:00:33  iter: 2719  total_loss: 1.113  loss_cls: 0.314  loss_box_reg: 0.2671  loss_mask: 0.342  loss_rpn_cls: 0.07176  loss_rpn_loc: 0.08752  time: 0.5806  data_time: 0.0181  lr: 0.0081584  max_mem: 4624M
[32m[11/12 18:58:21 d2.utils.events]: [0m eta: 14:01:03  iter: 2739  total_loss: 1.125  loss_cls: 0.3215  loss_box_reg: 0.2732  loss_mask: 0.3536  loss_rpn_cls: 0.09239  loss_rpn_loc: 0.1204  time: 0.5807  data_time: 0.0191  lr: 0.0082184  max_mem: 4624M
[32m[11/12 18:58:33 d2.utils.events]: [0m eta: 14:01:07  iter: 2759  total_loss: 1.134  loss_cls: 0.3115  loss_box_reg: 0.2718  loss_mask: 0.3377  loss_rpn_cls: 0.07809  loss_rpn_loc: 0.1055  time: 0.5808  data_time: 0.0189  lr: 0.0082783  max_mem: 4624M
[32m[11/12 18:58:44 d2.utils.events]: [0m eta: 14:01:40  iter: 2779  total_loss: 1.166  loss_cls: 0.3379  loss_box_reg: 0.2818  loss_mask: 0.3437  loss_rpn_cls: 0.07516  loss_rpn_loc: 0.09949  time: 0.5809  data_time: 0.0204  lr: 0.0083383  max_mem: 4624M
[32m[11/12 18:58:56 d2.utils.events]: [0m eta: 14:01:57  iter: 2799  total_loss: 1.026  loss_cls: 0.2803  loss_box_reg: 0.2439  loss_mask: 0.3332  loss_rpn_cls: 0.0756  loss_rpn_loc: 0.09376  time: 0.5809  data_time: 0.0196  lr: 0.0083983  max_mem: 4624M
[32m[11/12 18:59:08 d2.utils.events]: [0m eta: 14:01:17  iter: 2819  total_loss: 1.118  loss_cls: 0.3232  loss_box_reg: 0.2648  loss_mask: 0.3442  loss_rpn_cls: 0.08189  loss_rpn_loc: 0.09837  time: 0.5810  data_time: 0.0413  lr: 0.0084583  max_mem: 4624M
[32m[11/12 18:59:20 d2.utils.events]: [0m eta: 14:00:29  iter: 2839  total_loss: 1.106  loss_cls: 0.3022  loss_box_reg: 0.2693  loss_mask: 0.3272  loss_rpn_cls: 0.0899  loss_rpn_loc: 0.1212  time: 0.5810  data_time: 0.0212  lr: 0.0085183  max_mem: 4624M
[32m[11/12 18:59:32 d2.utils.events]: [0m eta: 14:00:22  iter: 2859  total_loss: 1.059  loss_cls: 0.2845  loss_box_reg: 0.2548  loss_mask: 0.3401  loss_rpn_cls: 0.08115  loss_rpn_loc: 0.0906  time: 0.5811  data_time: 0.0220  lr: 0.0085783  max_mem: 4624M
[32m[11/12 18:59:43 d2.utils.events]: [0m eta: 14:00:06  iter: 2879  total_loss: 1.145  loss_cls: 0.3178  loss_box_reg: 0.2683  loss_mask: 0.3512  loss_rpn_cls: 0.08208  loss_rpn_loc: 0.1  time: 0.5811  data_time: 0.0191  lr: 0.0086383  max_mem: 4624M
[32m[11/12 18:59:55 d2.utils.events]: [0m eta: 14:00:04  iter: 2899  total_loss: 1.194  loss_cls: 0.3397  loss_box_reg: 0.2991  loss_mask: 0.3467  loss_rpn_cls: 0.08717  loss_rpn_loc: 0.1183  time: 0.5812  data_time: 0.0170  lr: 0.0086983  max_mem: 4624M
[32m[11/12 19:00:07 d2.utils.events]: [0m eta: 14:00:45  iter: 2919  total_loss: 1.123  loss_cls: 0.318  loss_box_reg: 0.2871  loss_mask: 0.3314  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.08794  time: 0.5812  data_time: 0.0186  lr: 0.0087582  max_mem: 4624M
[32m[11/12 19:00:19 d2.utils.events]: [0m eta: 14:00:35  iter: 2939  total_loss: 1.063  loss_cls: 0.2868  loss_box_reg: 0.2766  loss_mask: 0.3388  loss_rpn_cls: 0.09137  loss_rpn_loc: 0.1022  time: 0.5813  data_time: 0.0164  lr: 0.0088182  max_mem: 4624M
[32m[11/12 19:00:30 d2.utils.events]: [0m eta: 13:59:47  iter: 2959  total_loss: 1.078  loss_cls: 0.2921  loss_box_reg: 0.2425  loss_mask: 0.3239  loss_rpn_cls: 0.08308  loss_rpn_loc: 0.09041  time: 0.5812  data_time: 0.0282  lr: 0.0088782  max_mem: 4624M
[32m[11/12 19:00:42 d2.utils.events]: [0m eta: 13:59:15  iter: 2979  total_loss: 1.119  loss_cls: 0.3152  loss_box_reg: 0.2842  loss_mask: 0.3375  loss_rpn_cls: 0.07736  loss_rpn_loc: 0.09538  time: 0.5813  data_time: 0.0178  lr: 0.0089382  max_mem: 4624M
[32m[11/12 19:00:54 d2.utils.events]: [0m eta: 13:59:59  iter: 2999  total_loss: 1.115  loss_cls: 0.306  loss_box_reg: 0.2633  loss_mask: 0.3344  loss_rpn_cls: 0.08773  loss_rpn_loc: 0.101  time: 0.5814  data_time: 0.0205  lr: 0.0089982  max_mem: 4624M
[32m[11/12 19:01:06 d2.utils.events]: [0m eta: 13:59:48  iter: 3019  total_loss: 1.04  loss_cls: 0.284  loss_box_reg: 0.2451  loss_mask: 0.3469  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.09586  time: 0.5814  data_time: 0.0226  lr: 0.0090582  max_mem: 4624M
[32m[11/12 19:01:18 d2.utils.events]: [0m eta: 13:59:48  iter: 3039  total_loss: 1.119  loss_cls: 0.3146  loss_box_reg: 0.2783  loss_mask: 0.3394  loss_rpn_cls: 0.08945  loss_rpn_loc: 0.09832  time: 0.5815  data_time: 0.0205  lr: 0.0091182  max_mem: 4624M
[32m[11/12 19:01:29 d2.utils.events]: [0m eta: 13:59:42  iter: 3059  total_loss: 1.11  loss_cls: 0.3092  loss_box_reg: 0.247  loss_mask: 0.3447  loss_rpn_cls: 0.08254  loss_rpn_loc: 0.1075  time: 0.5815  data_time: 0.0208  lr: 0.0091782  max_mem: 4624M
[32m[11/12 19:01:41 d2.utils.events]: [0m eta: 13:59:36  iter: 3079  total_loss: 1.176  loss_cls: 0.3292  loss_box_reg: 0.2822  loss_mask: 0.3558  loss_rpn_cls: 0.08985  loss_rpn_loc: 0.09807  time: 0.5815  data_time: 0.0217  lr: 0.0092382  max_mem: 4624M
[32m[11/12 19:01:53 d2.utils.events]: [0m eta: 14:00:58  iter: 3099  total_loss: 1.149  loss_cls: 0.3165  loss_box_reg: 0.2856  loss_mask: 0.3387  loss_rpn_cls: 0.09342  loss_rpn_loc: 0.1079  time: 0.5816  data_time: 0.0188  lr: 0.0092981  max_mem: 4624M
[32m[11/12 19:02:04 d2.utils.events]: [0m eta: 14:00:46  iter: 3119  total_loss: 1.063  loss_cls: 0.3056  loss_box_reg: 0.2555  loss_mask: 0.35  loss_rpn_cls: 0.08457  loss_rpn_loc: 0.0997  time: 0.5815  data_time: 0.0166  lr: 0.0093581  max_mem: 4624M
[32m[11/12 19:02:16 d2.utils.events]: [0m eta: 14:00:02  iter: 3139  total_loss: 1.137  loss_cls: 0.3388  loss_box_reg: 0.2834  loss_mask: 0.3468  loss_rpn_cls: 0.07855  loss_rpn_loc: 0.1027  time: 0.5816  data_time: 0.0169  lr: 0.0094181  max_mem: 4624M
[32m[11/12 19:02:28 d2.utils.events]: [0m eta: 14:00:55  iter: 3159  total_loss: 1.141  loss_cls: 0.3057  loss_box_reg: 0.2625  loss_mask: 0.3546  loss_rpn_cls: 0.0883  loss_rpn_loc: 0.1104  time: 0.5817  data_time: 0.0231  lr: 0.0094781  max_mem: 4624M
[32m[11/12 19:02:40 d2.utils.events]: [0m eta: 14:00:34  iter: 3179  total_loss: 1.059  loss_cls: 0.2997  loss_box_reg: 0.2642  loss_mask: 0.341  loss_rpn_cls: 0.0782  loss_rpn_loc: 0.09912  time: 0.5816  data_time: 0.0198  lr: 0.0095381  max_mem: 4624M
[32m[11/12 19:02:51 d2.utils.events]: [0m eta: 14:00:53  iter: 3199  total_loss: 1.103  loss_cls: 0.3091  loss_box_reg: 0.2698  loss_mask: 0.3329  loss_rpn_cls: 0.09014  loss_rpn_loc: 0.1024  time: 0.5816  data_time: 0.0220  lr: 0.0095981  max_mem: 4624M
[32m[11/12 19:03:03 d2.utils.events]: [0m eta: 14:00:33  iter: 3219  total_loss: 1.132  loss_cls: 0.3043  loss_box_reg: 0.2655  loss_mask: 0.3483  loss_rpn_cls: 0.07704  loss_rpn_loc: 0.09949  time: 0.5817  data_time: 0.0210  lr: 0.0096581  max_mem: 4624M
[32m[11/12 19:03:15 d2.utils.events]: [0m eta: 14:01:40  iter: 3239  total_loss: 1.18  loss_cls: 0.337  loss_box_reg: 0.2863  loss_mask: 0.3412  loss_rpn_cls: 0.09182  loss_rpn_loc: 0.117  time: 0.5817  data_time: 0.0179  lr: 0.0097181  max_mem: 4624M
[32m[11/12 19:03:27 d2.utils.events]: [0m eta: 14:01:54  iter: 3259  total_loss: 1.159  loss_cls: 0.3114  loss_box_reg: 0.3003  loss_mask: 0.3547  loss_rpn_cls: 0.09794  loss_rpn_loc: 0.09888  time: 0.5819  data_time: 0.0213  lr: 0.009778  max_mem: 4624M
[32m[11/12 19:03:39 d2.utils.events]: [0m eta: 14:01:43  iter: 3279  total_loss: 1.156  loss_cls: 0.3409  loss_box_reg: 0.2896  loss_mask: 0.3301  loss_rpn_cls: 0.08724  loss_rpn_loc: 0.09333  time: 0.5819  data_time: 0.0196  lr: 0.009838  max_mem: 4624M
